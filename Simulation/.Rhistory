a_S <- b_S <- 1
a_C <- b_C <- 1
# nStep <- 100
# nChain <- 8
Gibbs_unif <- Gibbs(nStep=10000, a=80, b=20)
par(mfrow=c(2, 2))
plot(density(Gibbs_info3$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info3$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info3$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
set.seed(51)
# 1
alpha <- 1
beta <- 1
curve(dbeta(x, alpha, beta), xlim=c(0, 1), main="Beta(1,1) prior")
n_samp <- 100
n_pp_samp <- 1000
thetas <- rbeta(n_pp_samp, alpha, beta)
n_samp <- 100
n_pp_samp <- 1000
thetas <- rbeta(n_pp_samp, alpha, beta)
samples <- rep(0, n_pp_samp)
for (i in 1:n_pp_samp) samples[i] <- rbinom(1, n_samp, thetas[i])
mean(samples)
# 2
k <- 6
n <- 100
(alpha_ <- alpha + k)
(beta_ <- beta + (n - k))
curve(dbeta(x, alpha_, beta_), xlim=c(0, 1), main="Beta(7,95) posterior")
(mean <- alpha_ / (alpha_ + beta_))
# 3
par(mfrow=c(1, 2))
# hist(rbeta(n_samp, alpha_, beta_))
plot(density(rbeta(n_samp, alpha_, beta_)), xlim=c(0, 0.15), main="100 samples fr. Beta(7,95)")
# hist(rbeta(n_samp, alpha_, beta_))
plot(density(rbeta(n_samp, alpha_, beta_)), xlim=c(0, 0.15), main="100 samples fr. Beta(7,95)")
# 3
par(mfrow=c(1, 2))
# hist(rbeta(n_samp, alpha_, beta_))
plot(density(rbeta(n_samp, alpha_, beta_)), xlim=c(0, 0.15), main="100 samples fr. Beta(7,95)")
curve(dbeta(x, alpha_, beta_), xlim=c(0, 0.15), main="Exact Beta(7,95)")
# 4
samp_mean <- rep(0, 10000)
for (n in 1:10000) {
samp_mean[n] <- mean(rbeta(n, alpha_, beta_))
}
plot(samp_mean, type="l", ylim=c(mean_-0.01, mean_+0.01), xlab="sample size", ylab="sample mean", main="Sample means for sample sizes")
abline(h=mean_, col="red")
par(mfrow=c(1, 1))
# 4
samp_mean <- rep(0, 10000)
for (n in 1:10000) {
samp_mean[n] <- mean(rbeta(n, alpha_, beta_))
}
plot(samp_mean, type="l", ylim=c(mean_-0.01, mean_+0.01), xlab="sample size", ylab="sample mean", main="Sample means for sample sizes")
abline(h=mean_, col="red")
# 5
(var_ <- (alpha_ * beta_) /
((alpha_ + beta_)^2 * (alpha_ + beta_ + 1))
)
samp_var <- rep(0, 1000)
for (n in 1:1000) {
samp_var[n] <- var(rbeta(100, alpha_, beta_))
}
plot(density(samp_var), xlab="variance", main="Dist. of sample vars (100 samples, 1000 iter)")
abline(v=var_, col="red")
set.seed(51)
alpha <- 1
beta <- 1
k <- 6
N <- 100
alpha_ <- alpha + k
beta_ <- beta + (N - k)
# 1
theta_prop <- function(theta, stepsize=0.01) {
theta_new <- rnorm(1, theta, stepsize)%%1
return(theta_new)
}
# 2
acc_rej <- function(theta_new, theta_now, k=6, N=100, alpha=1, beta=1) {
r <- (dbinom(k, N, theta_new) * dbeta(theta_new, alpha, beta)) / (dbinom(k, N, theta_now) * dbeta(theta_now, alpha, beta))
p <- runif(1, 0, 1)
theta_next <- ifelse(r > p, theta_new, theta_now)
return(theta_next)
}
# 3
rwm <- function(nSteps=100, stepsize=0.01, k=6, N=100, alpha=1, beta=1) {
theta_now <- runif(1, 0, 1)
theta <- rep(0, nSteps)
for (step in 1:nSteps) {
theta_new <- theta_prop(theta_now, stepsize)
theta_next <- acc_rej(theta_new, theta_now)
theta[step] <- theta_now <- theta_next
}
return(theta)
}
# 4
par(mfrow=c(1, 2))
nSteps <- 100
rwm_samples <- rwm(nSteps)
plot(density(rwm_samples), xlim=c(0, 1), main="RWM (100 samples)", xlab="Theta", ylab="Posterior samples")
plot(density(rwm_samples), xlim=c(0, 1), main="RWM (100 samples)", xlab="Theta", ylab="Posterior samples")
curve(dbeta(x, alpha_, beta_), xlim=c(0, 1), main="Exact Beta(7,95)", xlab="Theta", ylab="Density")
par(mfrow=c(1, 1))
# 5
nChains <- 1000
# 5
nChains <- 1000
mat_01 <- matrix(nrow=nChains, ncol=nSteps)
for (chain in 1:nChains) {
mat_01[chain, ] <- rwm(nSteps)
}
par(mfrow=c(1, 2))
plot(density(rowMeans(mat_01)), xlim=c(0, 1), main="Step size = 0.01", xlab="Theta", ylab="Sample means")
# 6
burnin <- 50
plot(density(rowMeans(mat_01[,-(1:burnin)])), xlim=c(0, 1), main="Step size = 0.01 (burnin)", xlab="Theta", ylab="Sample means")
par(mfrow=c(1, 1))
# 7
par(mfrow=c(1, 2))
mat_001 <- matrix(nrow=nChains, ncol=nSteps)
for (chain in 1:nChains) {
mat_001[chain, ] <- rwm(nSteps, 0.001)
}
plot(density(rowMeans(mat_001)), xlim=c(0, 1), main="Step size = 0.001", xlab="Theta", ylab="Sample means")
mat_1 <- matrix(nrow=nChains, ncol=nSteps)
for (chain in 1:nChains) {
mat_1[chain, ] <- rwm(nSteps, 0.1)
}
plot(density(rowMeans(mat_1)), xlim=c(0, 1), main="step size = 0.1", xlab="Theta", ylab="sample means")
par(mfrow=c(1, 1))
# 8
within <- function(mat) {
wChain_mean <- rowMeans(mat)
s2_j <- rep(0, nChains)
for (j in 1:nChains) {
s2_j[j] <- sum(mat[j, ] - rep(wChain_mean[j], nSteps)^2) / (nSteps - 1)
}
W <- sum(s2_j) / nChains
return (W)
}
between <- function(mat) {
wChain_mean <- rowMeans(mat)
gMean <- mean(mat)
B <- nSteps / (nChains - 1) * sum((wChain_mean - gMean)^2)
return (B)
}
Rhat <- function(mat) {
W <- within(mat)
B <- between(mat)
R <- sqrt((W + (B - W) / nSteps) / W)
return (R)
}
# 9
Rhat(mat_1)
Rhat(mat_01)
Rhat(mat_001)
set.seed(51)
# 2
Gibbs <- function(nStep, a, b, a_pi=1, b_pi=1, a_S=1, b_S=1, a_C=1, b_C=1) {
pi <- rep(0, nStep)
S <- rep(0, nStep)
C <- rep(0, nStep)
# prior
pi[1] <- rbeta(1, a_pi, b_pi)
S[1] <- rbeta(1, a_S, b_S)
C[1] <- rbeta(1, a_C, b_C)
for (step in 1:(nStep - 1)) {
# data
Y1 <- rbinom(1, a, (pi * S) / (pi * S + (1 - pi) * (1 - C)))
Y2 <- rbinom(1, b, (pi * (1 - S)) / (pi * (1 - S) + (1 - pi) * C))
# posterior
pi[step + 1] <- rbeta(1, Y1 + Y2 + a_pi, a + b - Y1 - Y2 + b_pi)
S[step + 1] <- rbeta(1, Y1 + a_S, Y2 + b_S)
C[step + 1] <- rbeta(1, b - Y2 + a_C, a - Y1 + b_C)
}
return (posterior <- list(pi=pi, S=S, C=C))
}
# 3
a <- 80
b <- 20
a_pi <- b_pi <- 1
a_S <- b_S <- 1
a_C <- b_C <- 1
# nStep <- 100
# nChain <- 8
Gibbs_unif <- Gibbs(nStep=10000, a=80, b=20)
par(mfrow=c(2, 2))
plot(density(Gibbs_info3$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info3$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info3$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# high positive predicted -> high sensitivity x low specificity
#
# 4
Gibbs_info4 <- Gibbs(nStep=10000, a=80, b=20, a_S=10, b_S=1, a_C=10, b_C=1)
par(mfrow=c(2, 2))
# 4
Gibbs_info4 <- Gibbs(nStep=10000, a=80, b=20, a_S=10, b_S=1, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info4$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info4$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info4$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 5
Gibbs_info5 <- Gibbs(nStep=10000, a=80, b=20, a_pi=1, b_pi=10)
set.seed(51)
# 2
Gibbs <- function(nStep, a, b, a_pi=1, b_pi=1, a_S=1, b_S=1, a_C=1, b_C=1) {
pi <- rep(0, nStep)
S <- rep(0, nStep)
C <- rep(0, nStep)
# prior
pi[1] <- rbeta(1, a_pi, b_pi)
S[1] <- rbeta(1, a_S, b_S)
C[1] <- rbeta(1, a_C, b_C)
for (step in 1:(nStep - 1)) {
# data
Y1 <- rbinom(1, a, (pi * S) / (pi * S + (1 - pi) * (1 - C)))
Y2 <- rbinom(1, b, (pi * (1 - S)) / (pi * (1 - S) + (1 - pi) * C))
# posterior
pi[step + 1] <- rbeta(1, Y1 + Y2 + a_pi, a + b - Y1 - Y2 + b_pi)
S[step + 1] <- rbeta(1, Y1 + a_S, Y2 + b_S)
C[step + 1] <- rbeta(1, b - Y2 + a_C, a - Y1 + b_C)
}
return (posterior <- list(pi=pi, S=S, C=C))
}
# 3
a <- 80
b <- 20
a_pi <- b_pi <- 1
a_S <- b_S <- 1
a_C <- b_C <- 1
# nStep <- 100
# nChain <- 8
Gibbs_unif <- Gibbs(nStep=10000, a=80, b=20)
par(mfrow=c(2, 2))
plot(density(Gibbs_info3$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info3$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info3$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# high positive predicted is reflected by the combination of high sensitivity and low specificity
# 4
Gibbs_info4 <- Gibbs(nStep=10000, a=80, b=20, a_S=10, b_S=1, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info4$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info4$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info4$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 5
Gibbs_info5 <- Gibbs(nStep=10000, a=80, b=20, a_pi=1, b_pi=10)
set.seed(51)
# 2
Gibbs <- function(nStep, a, b, a_pi=1, b_pi=1, a_S=1, b_S=1, a_C=1, b_C=1) {
pi <- rep(0, nStep)
S <- rep(0, nStep)
C <- rep(0, nStep)
# prior
pi[1] <- rbeta(1, a_pi, b_pi)
S[1] <- rbeta(1, a_S, b_S)
C[1] <- rbeta(1, a_C, b_C)
for (step in 1:(nStep - 1)) {
# data
Y1 <- rbinom(1, a, (pi * S) / (pi * S + (1 - pi) * (1 - C)))
Y2 <- rbinom(1, b, (pi * (1 - S)) / (pi * (1 - S) + (1 - pi) * C))
# posterior
pi[step + 1] <- rbeta(1, Y1 + Y2 + a_pi, a + b - Y1 - Y2 + b_pi)
S[step + 1] <- rbeta(1, Y1 + a_S, Y2 + b_S)
C[step + 1] <- rbeta(1, b - Y2 + a_C, a - Y1 + b_C)
}
return (posterior <- list(pi=pi, S=S, C=C))
}
# 3
a <- 80
b <- 20
a_pi <- b_pi <- 1
a_S <- b_S <- 1
a_C <- b_C <- 1
# nStep <- 100
# nChain <- 8
Gibbs_unif <- Gibbs(nStep=10000, a=80, b=20)
par(mfrow=c(2, 2))
plot(density(Gibbs_info3$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info3$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info3$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 4
Gibbs_info4 <- Gibbs(nStep=10000, a=80, b=20, a_S=10, b_S=1, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info4$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info4$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info4$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 5
Gibbs_info5 <- Gibbs(nStep=10000, a=80, b=20, a_pi=1, b_pi=10)
par(mfrow=c(2, 2))
plot(density(Gibbs_info5$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info5$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info5$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 6
Gibbs_info6 <- Gibbs(nStep=10000, a=80, b=20, a_pi=1, b_pi=10, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info6$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info6$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info6$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 7
Gibbs_info7 <- Gibbs(nStep=10000, a=800, b=200, a_pi=1, b_pi=10, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info7$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info7$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info7$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")# sharper
par(mfrow=c(1, 1))
set.seed(51)
# 2
Gibbs <- function(nStep, a, b, a_pi=1, b_pi=1, a_S=1, b_S=1, a_C=1, b_C=1) {
pi <- rep(0, nStep)
S <- rep(0, nStep)
C <- rep(0, nStep)
# prior
pi[1] <- rbeta(1, a_pi, b_pi)
S[1] <- rbeta(1, a_S, b_S)
C[1] <- rbeta(1, a_C, b_C)
for (step in 1:(nStep - 1)) {
# data
Y1 <- rbinom(1, a, (pi * S) / (pi * S + (1 - pi) * (1 - C)))
Y2 <- rbinom(1, b, (pi * (1 - S)) / (pi * (1 - S) + (1 - pi) * C))
# posterior
pi[step + 1] <- rbeta(1, Y1 + Y2 + a_pi, a + b - Y1 - Y2 + b_pi)
S[step + 1] <- rbeta(1, Y1 + a_S, Y2 + b_S)
C[step + 1] <- rbeta(1, b - Y2 + a_C, a - Y1 + b_C)
}
return (posterior <- list(pi=pi, S=S, C=C))
}
# 3
a <- 80
b <- 20
a_pi <- b_pi <- 1
a_S <- b_S <- 1
a_C <- b_C <- 1
# nStep <- 100
# nChain <- 8
Gibbs_unif <- Gibbs(nStep=10000, a=80, b=20)
par(mfrow=c(2, 2))
plot(density(Gibbs_info3$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info3$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info3$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 80% positive prediction is reflected by the combination of high S and low C and a small \pi
# 4
Gibbs_info4 <- Gibbs(nStep=10000, a=80, b=20, a_S=10, b_S=1, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info4$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info4$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info4$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# By an informative prior, S and C are shifted to higher values compared with #3.
# Together with 80% positive prediction, this results in a larger \pi
# 5
Gibbs_info5 <- Gibbs(nStep=10000, a=80, b=20, a_pi=1, b_pi=10)
par(mfrow=c(2, 2))
plot(density(Gibbs_info5$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info5$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info5$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# By an informative prior, \pi is expected to be small; while 80% are predicted positively.
# To reconcile this contradiction, small C is predicted (most of the positive predictions are actually negative).
# On the other hand, the sensitivity is still uncertain.
# 6
Gibbs_info6 <- Gibbs(nStep=10000, a=80, b=20, a_pi=1, b_pi=10, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info6$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info6$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info6$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")
par(mfrow=c(1, 1))
# 7
Gibbs_info7 <- Gibbs(nStep=10000, a=800, b=200, a_pi=1, b_pi=10, a_C=10, b_C=1)
par(mfrow=c(2, 2))
plot(density(Gibbs_info7$pi), xlim=c(0, 1), main="posterior of pi (prevalence)", xlab="pi", ylab="Density")
plot(density(Gibbs_info7$S), xlim=c(0, 1), main="posterior of S (sensitivity)", xlab="S", ylab="Density")
plot(density(Gibbs_info7$C), xlim=c(0, 1), main="posterior of C (specificity)", xlab="C", ylab="Density")# sharper
par(mfrow=c(1, 1))
1/2 * log(0.999/0.001)
1/2 * log(Inf)
library(evd)
library(ismev)
?venice2
head(venice2)
venice2[,1]
plot(1887:2011, venice2[,1], type="l")
plot(1887:2011, venice2[,1], type="l", ylim=c(0,200))
venice2[,1]
venice2[1,]
venice2[1,1]
venice2[2,1]
venice2[2,]
(venice.gev <- fgev(venice2[,1])) # GEVモデルを作る
par(mfrow=c(2,2))
plot(venice.gev) # EDA
fgev(venice2[,1],prob=0.01) # 100年期待最大値の推定
confint(venice.gev) # 信頼区間を求める。
venice.gev.i <- gev.fit(venice2[,1])
venice.rgev2 <- rlarg.fit(venice2,2)
venice3 <- c(as.matrix(venice2)) # ベクトルにする
mrlplot(venice3) # 事前EDA
par(mfrow=c(2,1))
tcplot(venice3,tlim=c(80,130)) # 事前EDA
venice3 <- c(as.matrix(venice2)) # ベクトルにする
mrlplot(venice3) # 事前EDA
par(mfrow=c(2,1))
tcplot(venice3,tlim=c(80,130)) # 事前EDA
(venice.pot <- fpot(venice3,100)) # GP推定
par(mfrow=c(2,2))
plot(venice.pot) # 事後EDA
(venice.pot2 <- fpot(venice3,120)) # GP推定
plot(venice.pot2) # 事後EDA
sum(venice3> 120, na.rm=T)
cuda_is_available()
library(torch)
cuda_is_available()
install.packages("torch")
print("hello")
library(torch)
cuda_is_available()
library(torch)
cuda_is_available()
torch::install_torch(cuda = "12.4")
torch::install_torch(cuda = "12.4")
torch::install_torch(cuda = "11.8")
install.packages("torch")
library(torch)
cuda_is_available()
torch::install_torch(cuda = "12.4")
torch::install_torch(cuda = "11.8")
install.packages("remotes")
remotes::install_github("mlverse/torch")
remotes::install_github("mlverse/torch")
torch::install_torch()
if (!require("rappdirs")) install.packages("rappdirs")
rappdirs::user_data_dir("torch")
library(torch)
cuda_is_available()
library(torch)
remove.packages("torch")
install.packages("torch")
library(torch)
cuda_is_available()
torch::install_torch(cuda = "12.1")
# Rを再起動してから実行してください
# reticulateに、先ほどPyTorchをインストールしたPythonの場所を教える
# Microsoft Storeからインストールした場合、通常はこのパスになります
reticulate::use_python("C:/Users/kento/AppData/Local/Microsoft/WindowsApps/python3.11.exe", required = TRUE)
# Rを再起動してから実行してください
# reticulateに、先ほどPyTorchをインストールしたPythonの場所を教える
# Microsoft Storeからインストールした場合、通常はこのパスになります
reticulate::use_python("C:/Users/kento/AppData/Local/Microsoft/WindowsApps/python3.11.exe", required = TRUE)
reticulate::use_python("C:/Users/kento/AppData/Local/Microsoft/WindowsApps/python3.exe", required = TRUE)
# コマンドプロンプトで見つけた、ご自身のPCの正しいパスに書き換えてください
reticulate::use_python("ここにコピーしたパスを貼り付け", required = TRUE)
# コマンドプロンプトで見つけた、ご自身のPCの正しいパスに書き換えてください
reticulate::use_python("C:\Users\kento\AppData\Local\Programs\Python\Python312\python.exe", required = TRUE)
# コマンドプロンプトで見つけた、ご自身のPCの正しいパスに書き換えてください
reticulate::use_python("C:/Users/kento/AppData/Local/Programs/Python/Python312/python.exe", required = TRUE)
# その後、最終確認へ
library(torch)
cuda_is_available()
remove.packages("torch")
remove.packages("reticulate")
# 手動で設置したフォルダも完全に削除
unlink(rappdirs::user_data_dir("torch"), recursive = TRUE)
install.packages("reticulate")
install.packages("torch")
# あなたのPCの正しいPythonを指定
reticulate::use_python("C:/Users/kento/AppData/Local/Programs/Python/Python312/python.exe", required = TRUE)
# torchをロード
library(torch)
# 最終確認
cuda_is_available()
install.packages("usethis")
usethis::edit_r_environ()
install.packages("reticulate")
install.packages("torch")
library(torch)
cuda_is_available()
reticulate::py_config()
exp(-1.5)
# Set the working directory
setwd("C:/Users/kento/OneDrive - UT Cloud (1)/PhD/Regime-switching/Simulation")
# --- NEW STEP ---
# Run this first to create the averaged parameter file for the simulation
source("create_simulation_parameters.R")
cat(" -> Modifying true_params_for_simulation.csv: Setting gamma1 to 3.5\n")
param_file_path <- "true_params_for_simulation.csv"
if (file.exists(param_file_path)) {
# Read the file (specifying stringsAsFactors = FALSE)
params_df <- read.csv(param_file_path, stringsAsFactors = FALSE)
# Find the value of gamma1 and replace it with 3.5
gamma1_index <- which(params_df$Parameter == "gamma1")
if (length(gamma1_index) > 0) {
original_value <- params_df$Value[gamma1_index[1]]
params_df$Value[gamma1_index[1]] <- 3.5
# Overwrite the file and save
write.csv(params_df, param_file_path, row.names = FALSE, quote = FALSE)
cat(paste0("  -> Successfully modified gamma1 from ", original_value, " to 3.5.\n"))
} else {
warning("  -> 'gamma1' not found in true_params_for_simulation.csv. File was not modified.\n")
}
} else {
warning(paste("  ->", param_file_path, "not found. Cannot modify gamma1.\n"))
}
